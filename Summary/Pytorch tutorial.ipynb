{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Pytorch turtorial\n",
    "(https://pytorch.org/tutorials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = torch.Size([5, 3])\n",
      "x.size()[0] = 5, x.size()[1] = 3\n",
      "x.size(0) = 5, x.size(1) = 3\n",
      "x[None, :].shape = torch.Size([1, 5, 3])\n",
      "x.unsqueeze(0).shape = torch.Size([1, 5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(5, 3, dtype=torch.float)\n",
    "# shape is the same as size()\n",
    "print(f\"x.shape = {x.size()}\")\n",
    "# two ways to get specified dimention size\n",
    "print(f\"x.size()[0] = {x.size()[0]}, x.size()[1] = {x.size()[1]}\")\n",
    "print(f\"x.size(0) = {x.size(0)}, x.size(1) = {x.size(1)}\")\n",
    "\n",
    "# two ways to extend dimension\n",
    "print(f\"x[None, :].shape = {x[None, :].shape}\")\n",
    "print(f\"x.unsqueeze(0).shape = {x.unsqueeze(0).shape}\")\n",
    "\n",
    "# tensor-version transpose\n",
    "y = x[None, :]\n",
    "y.permute(2, 0, 1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> `torch.Size` is in fact a tuple, so it supports all tuple operations.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4424, -1.1048, -0.3555],\n",
      "        [ 2.5575,  0.4598,  2.4088],\n",
      "        [ 2.0923, -0.6871, -1.3885],\n",
      "        [ 1.0288,  0.9461, -1.4477],\n",
      "        [-0.0394, -0.4372,  0.8955]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "y = torch.randn(5, 3, dtype=torch.float32)\n",
    "torch.add(x, y, out=result) # provide an output tensor as argument\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4682, -1.0492,  0.9279],\n",
      "        [ 1.2007, -0.7875,  0.0336],\n",
      "        [ 4.0369, -1.5190, -1.5482],\n",
      "        [-1.6552,  1.9363, -1.9971],\n",
      "        [ 0.5353, -0.7182, -2.8778]])\n"
     ]
    }
   ],
   "source": [
    "# add in-place\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>**Any operation that mutates a tensor in-place is post-fixed with an _.** For example: `x.copy_(y)`, `x.t_()`, will change x.</font> \n",
    "<br> We can use standard NumPy-like indexing with all tensors. \n",
    "<br> Resizing: If you want to resize/reshape tensor, you can use `torch.view` or `x.reshape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9163,  0.1696, -0.5352,  1.1087, -1.0501],\n",
      "        [-0.5731,  1.9382, -0.1344, -1.4246, -0.8032],\n",
      "        [-0.2371, -0.7252,  0.3698, -1.5893, -0.7280]])\n",
      "tensor([[ 0.9163,  0.1696, -0.5352,  1.1087, -1.0501],\n",
      "        [-0.5731,  1.9382, -0.1344, -1.4246, -0.8032],\n",
      "        [-0.2371, -0.7252,  0.3698, -1.5893, -0.7280]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(-1, 5)\n",
    "print(z)\n",
    "print(x.reshape(-1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertion between a Torch Tensor and a NumPy array:\n",
    "The Torch Tensor and NumPy array will <font color=red> share their underlying memory locations </font> (if the Torch Tensor is on CPU), and changing one will change the other.\n",
    "<br> All the Tensors on the CPU except a CharTensor support converting to NumPy and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = [2. 2. 2. 2. 2.]\n",
      "a.item() = 1.0\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "a.add_(1)\n",
    "print(f\"b = {b}\") # b will be affected if a is changed in-place\n",
    "a = torch.ones(1)\n",
    "print(f\"a.item() = {a.item()}\") \n",
    "# if there is only one element, then .item(), return Python scalar\n",
    "\n",
    "# two ways to convert from numpy to tensor\n",
    "# 1. \n",
    "c = torch.from_numpy(b)\n",
    "print(c)\n",
    "# 2. \n",
    "print(torch.tensor(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9942, 0.2375, 0.0825, 0.3230],\n",
       "        [0.0706, 0.7496, 0.6417, 0.2720],\n",
       "        [0.3835, 0.1154, 0.3078, 0.8634]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "b = np.random.random((3, 4))\n",
    "torch.tensor(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOGRAD: AUTOMATIC DIFFERENTIATION\n",
    "Central to all neural networks in PyTorch is the `autograd` package.<br>\n",
    "To prevent tracking history (and using memory), you can wrap the code block in `with torch.no_grad():`. <br>\n",
    "Each tensor has a `.grad_fn` attribute that references a Function that has created the Tensor (<font color=red>except for Tensors created by the user - their `grad_fn is None`)</font>.\n",
    "\n",
    "**Important attributes in Variables: data, requires_grad, grad_fn, grad**\n",
    "1. `grad_fn` is None for leaf Tensor, while its grad is a Tensor. \n",
    "2. `grad_fn` is not None for other tree-node Tensors, but there will be a warining if you access its grad: *warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.requires_grad = False\n",
      "a.requires_grad = True\n",
      "b.grad_fn = <SumBackward0 object at 0x125851c18>\n",
      "a.grad_fn = None\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "print(f\"a.requires_grad = {a.requires_grad}\")\n",
    "a.requires_grad_(True)\n",
    "print(f\"a.requires_grad = {a.requires_grad}\")\n",
    "b = (a * a).sum()\n",
    "print(f\"b.grad_fn = {b.grad_fn}\")\n",
    "print(f\"a.grad_fn = {a.grad_fn}\") # leaf node, no grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.grad = tensor([[-0.3382, -1.4165],\n",
      "        [ 1.4241, -0.3048]])\n",
      "b.grad = None\n"
     ]
    }
   ],
   "source": [
    "b.backward()\n",
    "print(f\"a.grad = {a.grad}\")\n",
    "print(f\"b.grad = {b.grad}\")  \n",
    "# Non-leaf node's .grad attribute won't be populated during autograd.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By default, gradients are only retained for leaf variables. non-leaf variables' gradients are not retained to be inspected later. This was done by design, to save memory.** In order to get the non-leaf variables' gradients, you could call `.retain_grad()` before `.backward()`. \n",
    "\n",
    "**By default, `.baclward()` is only used on a scalar valued Tensor.** If you'd like to call backward on a vector function, you can pass a `torch.ones` of size of shape of the tensor you are trying to call backward with.\n",
    "`L.backward(torch.ones_like(L))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.grad = tensor([[-3.4189,  1.5920],\n",
      "        [ 3.7105,  0.9097]])\n",
      "b.grad = tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a.requires_grad = True\n",
    "b = a * a\n",
    "c = (b + a).sum()\n",
    "b.retain_grad()   \n",
    "# with this setting, we have dc/db; otherwise, the gradient of non-leaf node is not retained\n",
    "c.backward()\n",
    "print(f\"a.grad = {a.grad}\")\n",
    "print(f\"b.grad = {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One example that `retain_graph` is True:**\n",
    "<img src=\"./img/retain_graph.png\" alt=\"drawing\" width=\"500\"/>\n",
    "```\n",
    "loss1.backward(retain_graph=True)\n",
    "loss2.backward()\n",
    "opt.step()\n",
    "```\n",
    "Another simple way is:\n",
    "```\n",
    "total_loss = loss1 + loss2\n",
    "total_loss.backward()\n",
    "opt.step()\n",
    "```\n",
    "Essentially, they are the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "`torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample. <br>\n",
    "For example, `nn.Conv2d` will take in a 4D Tensor of `nSamples x nChannels x Height x Width`.\n",
    "If you have a single sample, just use `input.unsqueeze(0)` to add a fake batch dimension.\n",
    "\n",
    "If you follow `loss` in the backward direction, using its `.grad_fn` attribute, you will see a graph of computations.  \n",
    "```\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general way to set up weight decay for parameters:\n",
    "<img src=\"../img/weight_decay.png\" alt=\"drawing\" width=\"750\"/>\n",
    "For the weight parameters in the model, we use $l_2$ normaliztion. Thus we separate the parameters in the net into two groups and set individual attributes. <br>\n",
    "The attributes of each group consist of: \n",
    "<img src=\"../img/sgd_attr.png\" alt=\"drawing\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `torchvision` datasets are **PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].**\n",
    "```\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A typical way to construct a model:** \n",
    "```\n",
    "rgnet = nn.Sequential()\n",
    "rgnet.add_module('model',block())\n",
    "rgnet.add_module('Last_linear_layer', nn.Linear(16,10))\n",
    "rgnet.apply(init_weights)\n",
    "```\n",
    "where `block()` is an `nn.Sequential()` model as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save & load model \n",
    "```\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>**Three ways to access the network parameter values:**</font>\n",
    "1. `net[0].weight`; \n",
    "2. `net.Linear_1.weight`;\n",
    "3. `net.state_dict()['Linear_1.weight']` . `state_dict` is a method, while `state_dict()` returns a geneartor of OrderedDict of net parameter values. \n",
    "\n",
    "<font color=red>`net.parameters` is a method that show the net structure, which is similar to `net.state_dict`. `net.parameters()` is a generator object that can be iterated with `for`. `net.state_dict()` returns a generator of OrderDict. \n",
    "\n",
    "Another difference is that attribute `requires_grad` in parameters of `net.parameters()` are `True`, while in `net.state_dict()` it is `false. `</font>\n",
    "\n",
    "#### <font color=red> Three ways to iterate all the net parameters</font>\n",
    "1. `for param in net.parameters()`, `param.size(), param.data, param.dtype`;\n",
    "2. `for key, value in net.state_dict().items()`, `value` is a Tensor, equivalent to `param.data`;\n",
    "3. `for name, param in net.named_parameters()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double check the structure of the net\n",
    "Show the output shape of each layer:\n",
    "```\n",
    "X = torch.randn(size=(1,1,28,28), dtype = torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)\n",
    "```\n",
    "The result is as follows:\n",
    "```\n",
    "Reshape output shape: \t torch.Size([1, 1, 28, 28])\n",
    "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
    "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
    "AvgPool2d output shape:  torch.Size([1, 6, 14, 14])\n",
    "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
    "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
    "AvgPool2d output shape:  torch.Size([1, 16, 5, 5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways to fine tune\n",
    "freeze part of your model and train the rest:\n",
    "https://stackoverflow.com/questions/51748138/pytorch-how-to-set-requires-grad-false\n",
    "\n",
    "<font color=red>**Three ways of fine tuning:**</font>\n",
    "1. replace the specified layers in the pre-trained model, and only set the `requires_grad` of parameters in those layers as `True`. \n",
    "2. use `with torch.no_grad()`. \n",
    "3. put the parameters in the specified layers in `optim`. For instance, `optimizer = optim.SGD(net.linear1.parameters(), lr)`, in this case, thought the `grad` of the parameters in other layers are computed, those parameters are never updated in `optimizer.step()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear1', nn.Linear(2, 4))\n",
    "net.add_module('relu', nn.ReLU())\n",
    "net.add_module('linear2', nn.Linear(4, 1))\n",
    "\n",
    "X = torch.randn(size=(10, 2), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight:\n",
      "tensor([[-0.1355, -0.2333],\n",
      "        [-0.4334,  0.3797],\n",
      "        [ 0.4248, -0.0101],\n",
      "        [ 0.6089, -0.4895]])\n",
      "linear2.weight:\n",
      "tensor([[ -0.1188,  -0.9971,  -5.9006, -20.4001]])\n",
      "linear1.weight:\n",
      "tensor([[-0.1355, -0.2333],\n",
      "        [-0.4334,  0.3797],\n",
      "        [ 0.4248, -0.0101],\n",
      "        [ 0.6089, -0.4895]])\n",
      "linear2.weight:\n",
      "tensor([[-0.1188,  5.8125, 23.5612, 80.6392]])\n",
      "linear1.weight: grad tensor([[ 0.0000e+00,  0.0000e+00],\n",
      "        [-7.4132e-01,  1.0638e+01],\n",
      "        [ 2.8740e+02, -1.1358e+02],\n",
      "        [ 7.9221e+02, -7.0597e+02]])\n",
      "linear2.weight: grad tensor([[   0.0000,   -6.8095,  -29.4619, -101.0393]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(size=(10, 1), dtype=torch.float32)\n",
    "loss = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = optim.SGD(net.linear2.parameters(), lr=1)\n",
    "print(f\"linear1.weight:\\n{net.linear1.weight.data}\")\n",
    "print(f\"linear2.weight:\\n{net.linear2.weight.data}\")\n",
    "optimizer.zero_grad()\n",
    "l = loss(net(X), y)\n",
    "l.backward()\n",
    "optimizer.step()\n",
    "print(f\"linear1.weight:\\n{net.linear1.weight.data}\")\n",
    "print(f\"linear2.weight:\\n{net.linear2.weight.data}\")\n",
    "print(f\"linear1.weight: grad {net.linear1.weight.grad}\")\n",
    "print(f\"linear2.weight: grad {net.linear2.weight.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用Google Colab跑Jupyter Notebook:\n",
    "https://colab.research.google.com/github/haoysRPI/d2l-pytorch/blob/master/Ch06_Multilayer_Perceptrons/6_1_Multilayer_Perceptron.ipynb \n",
    "只需把后面部分换掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
