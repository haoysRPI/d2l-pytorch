{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Pytorch turtorial\n",
    "(https://pytorch.org/tutorials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = torch.Size([5, 3])\n",
      "x.size()[0] = 5, x.size()[1] = 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(5, 3, dtype=torch.float)\n",
    "print(f\"x.shape = {x.size()}\")\n",
    "print(f\"x.size()[0] = {x.size()[0]}, x.size()[1] = {x.size()[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> `torch.Size` is in fact a tuple, so it supports all tuple operations.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0173,  0.7390, -1.9385],\n",
      "        [-1.3984,  1.1377,  1.3435],\n",
      "        [-0.1264,  0.3964,  3.0010],\n",
      "        [ 3.2115, -1.3093,  0.3868],\n",
      "        [ 0.3710, -0.7705,  0.4424]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "y = torch.randn(5, 3, dtype=torch.float)\n",
    "torch.add(x, y, out=result) # provide an output tensor as argument\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0173,  0.7390, -1.9385],\n",
      "        [-1.3984,  1.1377,  1.3435],\n",
      "        [-0.1264,  0.3964,  3.0010],\n",
      "        [ 3.2115, -1.3093,  0.3868],\n",
      "        [ 0.3710, -0.7705,  0.4424]])\n"
     ]
    }
   ],
   "source": [
    "# add in-place\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>**Any operation that mutates a tensor in-place is post-fixed with an _.** For example: `x.copy_(y)`, `x.t_()`, will change x.</font> \n",
    "<br> We can use standard NumPy-like indexing with all tensors. \n",
    "<br> Resizing: If you want to resize/reshape tensor, you can use `torch.view` or `x.reshape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5424, -0.6362, -1.9036, -1.7576,  0.6408],\n",
      "        [ 0.9333, -0.1417, -0.0428,  0.3181,  3.1830],\n",
      "        [-0.9809,  0.6009,  1.1706,  1.0136, -0.3764]])\n",
      "tensor([[-0.5424, -0.6362, -1.9036, -1.7576,  0.6408],\n",
      "        [ 0.9333, -0.1417, -0.0428,  0.3181,  3.1830],\n",
      "        [-0.9809,  0.6009,  1.1706,  1.0136, -0.3764]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(-1, 5)\n",
    "print(z)\n",
    "print(x.reshape(-1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertion between a Torch Tensor and a NumPy array:\n",
    "The Torch Tensor and NumPy array will <font color=red> share their underlying memory locations </font> (if the Torch Tensor is on CPU), and changing one will change the other.\n",
    "<br> All the Tensors on the CPU except a CharTensor support converting to NumPy and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = [2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "a.add_(1)\n",
    "print(f\"b = {b}\") # b will be affected if a is changed in-place\n",
    "c = torch.from_numpy(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOGRAD: AUTOMATIC DIFFERENTIATION\n",
    "Central to all neural networks in PyTorch is the `autograd` package.<br>\n",
    "To prevent tracking history (and using memory), you can wrap the code block in `with torch.no_grad():`. <br>\n",
    "Each tensor has a `.grad_fn` attribute that references a Function that has created the Tensor (<font color=red>except for Tensors created by the user - their `grad_fn is None`)</font>.\n",
    "\n",
    "**Important attributes in Variables: data, requires_grad, grad_fn, grad**\n",
    "1. `grad_fn` is None for leaf Tensor, while its grad is a Tensor. \n",
    "2. `grad_fn` is not None for other tree-node Tensors, but there will be a warining if you access its grad: *warnings.warn(\"The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad \"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.requires_grad = False\n",
      "a.requires_grad = True\n",
      "b.grad_fn = <SumBackward0 object at 0x125db30b8>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "print(f\"a.requires_grad = {a.requires_grad}\")\n",
    "a.requires_grad_(True)\n",
    "print(f\"a.requires_grad = {a.requires_grad}\")\n",
    "b = (a * a).sum()\n",
    "print(f\"b.grad_fn = {b.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.grad = tensor([[ 1.1097,  0.2849],\n",
      "        [-1.8266, -1.2235]])\n",
      "b.grad = None\n"
     ]
    }
   ],
   "source": [
    "b.backward()\n",
    "print(f\"a.grad = {a.grad}\")\n",
    "print(f\"b.grad = {b.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.grad = tensor([[ 2.2193,  0.5699],\n",
      "        [-3.6532, -2.4469]])\n",
      "b.grad = None\n"
     ]
    }
   ],
   "source": [
    "b = (a * a).sum()\n",
    "b.backward(torch.ones_like(b))\n",
    "print(f\"a.grad = {a.grad}\")\n",
    "print(f\"b.grad = {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "`torch.nn` only supports mini-batches. The entire `torch.nn` package only supports inputs that are a mini-batch of samples, and not a single sample. <br>\n",
    "For example, `nn.Conv2d` will take in a 4D Tensor of `nSamples x nChannels x Height x Width`.\n",
    "If you have a single sample, just use `input.unsqueeze(0)` to add a fake batch dimension.\n",
    "\n",
    "If you follow `loss` in the backward direction, using its `.grad_fn` attribute, you will see a graph of computations.  \n",
    "```\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `torchvision` datasets are **PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].**\n",
    "```\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save & load model \n",
    "```\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
